{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/fabio/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/viva/analysis/salsa/salsa.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.233.225.83/opt/viva/analysis/salsa/salsa.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m labels \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.233.225.83/opt/viva/analysis/salsa/salsa.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Step 3: Reduce Dimensionality using t-SNE\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B35.233.225.83/opt/viva/analysis/salsa/salsa.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m tsne_embeddings \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(all_embeddings)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.233.225.83/opt/viva/analysis/salsa/salsa.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Step 4: Plot the Reduced Embeddings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B35.233.225.83/opt/viva/analysis/salsa/salsa.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m8\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1108\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1089\u001b[0m     \u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \n\u001b[1;32m   1091\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m   1109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n\u001b[1;32m   1110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:947\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    941\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m[t-SNE] Indexed \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m samples in \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39ms...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    942\u001b[0m             n_samples, duration\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m     )\n\u001b[1;32m    946\u001b[0m t0 \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 947\u001b[0m distances_nn \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mkneighbors_graph(mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdistance\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    948\u001b[0m duration \u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    949\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:886\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m    883\u001b[0m     A_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(n_queries \u001b[39m*\u001b[39m n_neighbors)\n\u001b[1;32m    885\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 886\u001b[0m     A_data, A_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, n_neighbors, return_distance\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    887\u001b[0m     A_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(A_data)\n\u001b[1;32m    889\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 752\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    753\u001b[0m         pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m             X,\n\u001b[1;32m    755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    756\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[1;32m    757\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    758\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    759\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m     )\n\u001b[1;32m    763\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    764\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:1717\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 1717\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1718\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1719\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1721\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:1889\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   1887\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 1889\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:1430\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1427\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1429\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1430\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1432\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:330\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m Y_norm_squared\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39m1\u001b[39m, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible dimensions for Y of shape \u001b[39m\u001b[39m{\u001b[39;00mY\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mY_norm_squared of shape \u001b[39m\u001b[39m{\u001b[39;00moriginal_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m         )\n\u001b[0;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:368\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    363\u001b[0m         YY \u001b[39m=\u001b[39m row_norms(Y, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[np\u001b[39m.\u001b[39mnewaxis, :]\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat32:\n\u001b[1;32m    366\u001b[0m     \u001b[39m# To minimize precision issues with float32, we compute the distance\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[39m# matrix on chunks of X and Y upcast to float64\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:559\u001b[0m, in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    556\u001b[0m     d \u001b[39m=\u001b[39m distances[y_slice, x_slice]\u001b[39m.\u001b[39mT\n\u001b[1;32m    558\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m     Y_chunk \u001b[39m=\u001b[39m Y[y_slice]\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[1;32m    560\u001b[0m     \u001b[39mif\u001b[39;00m YY \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m         YY_chunk \u001b[39m=\u001b[39m row_norms(Y_chunk, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[np\u001b[39m.\u001b[39mnewaxis, :]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clip_embedding_cache = {}\n",
    "\n",
    "def _load_embedding(clip_embedding_path):\n",
    "    filename, index = clip_embedding_path.split(\"#\")\n",
    "    index = int(index)\n",
    "\n",
    "    # Load Numpy array from file or cache\n",
    "    if filename not in clip_embedding_cache:\n",
    "        arr = np.load(f'/opt/viva/output/embeddings/{filename}')\n",
    "        clip_embedding_cache[filename] = arr\n",
    "    else:\n",
    "        arr = clip_embedding_cache[filename]\n",
    "        \n",
    "    # Extract row vector\n",
    "    row = arr[index]\n",
    "\n",
    "    return row\n",
    "\n",
    "# Step 1: Load the Parquet File\n",
    "required_columns = ['local_id', 'score', 'clip_embedding', 'label']\n",
    "df = pd.read_parquet('/opt/viva/analysis/results/results_variable,ucf101,clc@0.1,drumming-otherstuff', columns=required_columns)\n",
    "\n",
    "\n",
    "# Find the index of the highest score for each frame\n",
    "idx = df.groupby('local_id')['score'].idxmax()\n",
    "\n",
    "# Filter the DataFrame using these indices\n",
    "filtered_df = df.loc[idx]\n",
    "\n",
    "# Step 2: Extract Embeddings and Labels\n",
    "all_embeddings = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    file_name = row['clip_embedding'].split('#')[0]\n",
    "    actual_file_name = file_name.split('/')[-1]\n",
    "    embedding_index = int(row['clip_embedding'].split('#')[-1])  # again, adjust as necessary\n",
    "    file_name = actual_file_name + '#' + str(embedding_index)\n",
    "    embedding = _load_embedding(file_name)\n",
    "    all_embeddings.append(embedding)\n",
    "\n",
    "all_embeddings = np.array(all_embeddings)\n",
    "labels = df['label'].values\n",
    "\n",
    "# Step 3: Reduce Dimensionality using t-SNE\n",
    "tsne_embeddings = TSNE(n_components=2).fit_transform(all_embeddings)\n",
    "\n",
    "# Step 4: Plot the Reduced Embeddings\n",
    "plt.figure(figsize=(10,8))\n",
    "scatter = plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], c=labels, cmap='jet')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('t-SNE Visualization of Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, _ = clip.load('ViT-B/32', device=device)\n",
    "\n",
    "reference_labels = [\n",
    "    \"Human-Object Interaction\", \n",
    "    \"Body-Motion Only\", \n",
    "    \"Human-Human Interaction\", \n",
    "    \"Playing Musical Instruments\", \n",
    "    \"Sports\"\n",
    "]\n",
    "\n",
    "# 2. Tokenize and encode the reference_labels\n",
    "texts = clip.tokenize(reference_labels).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = model.encode_text(texts).cpu().numpy()\n",
    "\n",
    "# 3. Write the embeddings to the specified path\n",
    "os.makedirs('/opt/viva/tmp/embeddings', exist_ok=True)\n",
    "\n",
    "for label, embedding in zip(reference_labels, text_embeddings):\n",
    "    filename = label.lower().replace(\" \", \"_\") + \".npy\"\n",
    "    filepath = os.path.join('/opt/viva/tmp/embeddings', filename)\n",
    "    np.save(filepath, embedding)\n",
    "\n",
    "print(\"Embeddings saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/fabio/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from shutil import copy2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "clip_embedding_cache = {}\n",
    "  \n",
    "# Update _load_embedding to ensure it returns float64 data\n",
    "def _load_embedding(clip_embedding_path):\n",
    "    filename, index = clip_embedding_path.split(\"#\")\n",
    "    index = int(index)\n",
    "    embedding_file_name = filename.split(\"/\")[-1]\n",
    "\n",
    "    # Load Numpy array from file or cache\n",
    "    if filename not in clip_embedding_cache:\n",
    "        arr = np.load(f'/opt/viva/output/embeddings/{embedding_file_name}')\n",
    "        clip_embedding_cache[f'/opt/viva/output/embeddings/{embedding_file_name}'] = arr\n",
    "    else:\n",
    "        arr = clip_embedding_cache[f'/opt/viva/output/embeddings/{embedding_file_name}']\n",
    "        \n",
    "    # Extract row vector\n",
    "    row = arr[index]\n",
    "\n",
    "    return row\n",
    "\n",
    "# Load all embeddings\n",
    "directory = '/opt/viva/output/embeddings'\n",
    "embedding_files = [f for f in os.listdir(directory) if f.startswith('ucf101')]\n",
    "embeddings = [np.load(os.path.join(directory, file)) for file in embedding_files]\n",
    "all_embeddings = np.concatenate(embeddings, axis=0)\n",
    "all_embeddings = all_embeddings.astype(np.float64)\n",
    "\n",
    "# Perform t-SNE dimensionality reduction\n",
    "tsne = TSNE(n_components=3)\n",
    "projected_embeddings = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# Cluster the data into, e.g., 5 clusters using K-means\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters).fit(projected_embeddings)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Calculate the mean embedding for each cluster\n",
    "mean_embeddings = []\n",
    "for i in range(n_clusters):\n",
    "    cluster_embeddings = all_embeddings[labels == i]\n",
    "    mean_embedding = np.mean(cluster_embeddings, axis=0)\n",
    "    mean_embeddings.append(mean_embedding)\n",
    "mean_embeddings = np.array(mean_embeddings)\n",
    "\n",
    "# Load reference embeddings\n",
    "reference_labels = [\n",
    "    \"Human-Object Interaction\", \n",
    "    \"Body-Motion Only\", \n",
    "    \"Human-Human Interaction\", \n",
    "    \"Playing Musical Instruments\", \n",
    "    \"Sports\"\n",
    "]\n",
    "\n",
    "reference_filenames = [label.lower().replace(\" \", \"_\") + \".npy\" for label in reference_labels]\n",
    "reference_embeddings_path = '/opt/viva/tmp/embeddings'\n",
    "reference_embeddings = [np.load(os.path.join(reference_embeddings_path, filename)) for filename in reference_filenames]\n",
    "reference_embeddings = np.vstack(reference_embeddings)\n",
    "\n",
    "# Compute similarity to reference embeddings\n",
    "similarities = cosine_similarity(mean_embeddings, reference_embeddings)\n",
    "\n",
    "# Assign each embedding to the reference label with the highest similarity for its cluster\n",
    "embedding_assignments = []\n",
    "for label in labels:\n",
    "    # Get the index of the most similar reference label for the cluster\n",
    "    similar_label_idx = np.argmax(similarities[label])\n",
    "    embedding_assignments.append(similar_label_idx)\n",
    "    \n",
    "category_assignments = [reference_labels[i] for i in embedding_assignments]\n",
    "\n",
    "category_colors = {\n",
    "    \"Human-Object Interaction\": \"red\",\n",
    "    \"Body-Motion Only\": \"blue\",\n",
    "    \"Human-Human Interaction\": \"green\",\n",
    "    \"Playing Musical Instruments\": \"yellow\",\n",
    "    \"Sports\": \"purple\"\n",
    "}\n",
    "\n",
    "point_colors = [category_colors[category] for category in category_assignments]\n",
    "    \n",
    "  # Create the 3D scatter plot\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=projected_embeddings[:, 0],\n",
    "#     y=projected_embeddings[:, 1],\n",
    "#     z=projected_embeddings[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=5,\n",
    "#         color=point_colors,  # Set color to an array/list of desired values\n",
    "#         opacity=0.8\n",
    "#     ),\n",
    "#     text=category_assignments  # This will show the category name when hovering over a point\n",
    "# )])\n",
    "\n",
    "# # Update the layout and show the figure\n",
    "# fig.update_layout(\n",
    "#     margin=dict(l=0, r=0, b=0, t=0),\n",
    "#     scene=dict(\n",
    "#         xaxis_title=\"X Axis\",\n",
    "#         yaxis_title=\"Y Axis\",\n",
    "#         zaxis_title=\"Z Axis\"\n",
    "#     ),\n",
    "#     legend_title_text=\"Reference Labels\"\n",
    "# )\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "results_df = pd.read_parquet('/opt/viva/analysis/results/results_variable,ucf101,clc@0.1,drumming-otherstuff')\n",
    "results_df = results_df.drop_duplicates(subset=['frameuri'])\n",
    "\n",
    "from shutil import copy2\n",
    "\n",
    "# 1. Cluster the data in original embedding space\n",
    "kmeans_high_dim = KMeans(n_clusters=n_clusters).fit(all_embeddings)\n",
    "\n",
    "# 2. Calculate mean embeddings for each cluster in this space\n",
    "mean_embeddings_high_dim = []\n",
    "for i in range(n_clusters):\n",
    "    cluster_embeddings = all_embeddings[kmeans_high_dim.labels_ == i]\n",
    "    mean_embedding = np.mean(cluster_embeddings, axis=0)\n",
    "    mean_embeddings_high_dim.append(mean_embedding)\n",
    "mean_embeddings_high_dim = np.array(mean_embeddings_high_dim)\n",
    "\n",
    "# Compute similarity to reference embeddings for the high-dimensional cluster centers\n",
    "similarities_high_dim = cosine_similarity(mean_embeddings_high_dim, reference_embeddings)\n",
    "\n",
    "# Directory to save the sports images\n",
    "save_dir = '/opt/viva/tmp/ucf101'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Go through each row in results_df\n",
    "for _, row in results_df.iterrows():\n",
    "    # Load the embedding using the function you provided\n",
    "    embedding = _load_embedding(row['clip_embedding'])\n",
    "    \n",
    "    # Get the cluster label for this embedding\n",
    "    label = kmeans_high_dim.predict([embedding])[0]\n",
    "    \n",
    "    # Get the category assignment for this label\n",
    "    category = reference_labels[np.argmax(similarities_high_dim[label])]\n",
    "    \n",
    "    # Check if the category is \"Sports\"\n",
    "    if category == \"Sports\":\n",
    "        # Save the associated image\n",
    "        # Assuming the path to the image in results_df is 'image_path'\n",
    "        image_path = row['frameuri']\n",
    "        destination_path = os.path.join(save_dir, f\"sports_{os.path.basename(image_path)}\")\n",
    "        copy2(image_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Define source and destination directories\n",
    "source_dir = '/opt/viva/tmp/ucf101_frames_npy'\n",
    "destination_dir = '/opt/viva/tmp/ucf101_sport_images'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "\n",
    "# Iterate through each file in the source directory\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Load the numpy array\n",
    "        frame_array = np.load(os.path.join(source_dir, filename))\n",
    "        frame = cv2.cvtColor(frame_array, cv2.COLOR_BGR2RGB)\n",
    "        # Convert the numpy array to an image\n",
    "        image = Image.fromarray(frame_array.astype('uint8'))\n",
    "        \n",
    "        \n",
    "        # Save the image to the destination directory\n",
    "        # Assuming the filenames are like 'frame_001.npy', 'frame_002.npy', etc.\n",
    "        # The images will be saved as 'frame_001.jpg', 'frame_002.jpg', etc.\n",
    "        image_name = os.path.splitext(filename)[0] + '.jpg'\n",
    "        image_path = os.path.join(destination_dir, image_name)\n",
    "        image.save(image_path)\n",
    "\n",
    "print(\"Conversion completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
